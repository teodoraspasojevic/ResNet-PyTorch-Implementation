{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM1VkxuzZqFJNb8GUr9H5SE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teodoraspasojevic/ResNet-PyTorch-Implementation/blob/main/train_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtxhnOm1Qu80",
        "outputId": "64195351-bbfa-4034-d919-e7396da234a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/teodoraspasojevic/ResNet-PyTorch-Implementation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fpt8q_wRcsR",
        "outputId": "426f60e3-9285-41c1-caf7-9a1f7ce1602c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ResNet-PyTorch-Implementation'...\n",
            "remote: Enumerating objects: 4161, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 4161 (delta 2), reused 3 (delta 1), pack-reused 4150\u001b[K\n",
            "Receiving objects: 100% (4161/4161), 631.42 MiB | 16.90 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Updating files: 100% (4045/4045), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ResNet-PyTorch-Implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtB5F7rZRrGj",
        "outputId": "de97e51e-d8ba-4025-e87e-592cd0d148d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ResNet-PyTorch-Implementation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd src_to_implement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O93wMUnRRx4t",
        "outputId": "13d39682-cc8d-4aa4-f193-1a7cb77ebbb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ResNet-PyTorch-Implementation/src_to_implement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdD1lQrGR9Kj",
        "outputId": "b9719728-1fca-427f-aacc-2a9079726084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Loss: 0.65753, Validation Loss: 0.38246, Training F1: 0.06380, Validation F1: 0.00000\n",
            "Epoch 1: Training Loss: 0.34832, Validation Loss: 0.33473, Training F1: 0.12420, Validation F1: 0.20567\n",
            "Epoch 2: Training Loss: 0.33203, Validation Loss: 0.38345, Training F1: 0.16893, Validation F1: 0.29016\n",
            "Epoch 3: Training Loss: 0.33061, Validation Loss: 0.33774, Training F1: 0.19530, Validation F1: 0.17730\n",
            "Epoch 4: Training Loss: 0.33290, Validation Loss: 0.31686, Training F1: 0.17803, Validation F1: 0.20455\n",
            "Epoch 5: Training Loss: 0.32002, Validation Loss: 0.30964, Training F1: 0.19120, Validation F1: 0.26000\n",
            "Epoch 6: Training Loss: 0.31964, Validation Loss: 0.30898, Training F1: 0.20037, Validation F1: 0.20741\n",
            "Epoch 7: Training Loss: 0.31308, Validation Loss: 0.31101, Training F1: 0.21273, Validation F1: 0.26994\n",
            "Epoch 8: Training Loss: 0.31411, Validation Loss: 0.32401, Training F1: 0.17803, Validation F1: 0.29651\n",
            "Epoch 9: Training Loss: 0.30774, Validation Loss: 0.36693, Training F1: 0.19929, Validation F1: 0.00000\n",
            "Epoch 10: Training Loss: 0.31157, Validation Loss: 0.32406, Training F1: 0.21429, Validation F1: 0.16923\n",
            "Epoch 11: Training Loss: 0.30086, Validation Loss: 0.29427, Training F1: 0.22575, Validation F1: 0.28659\n",
            "Epoch 12: Training Loss: 0.30001, Validation Loss: 0.64110, Training F1: 0.25034, Validation F1: 0.06870\n",
            "Epoch 13: Training Loss: 0.30704, Validation Loss: 0.29208, Training F1: 0.22491, Validation F1: 0.27632\n",
            "Epoch 14: Training Loss: 0.29373, Validation Loss: 0.30194, Training F1: 0.31372, Validation F1: 0.26429\n",
            "Epoch 15: Training Loss: 0.29390, Validation Loss: 0.35074, Training F1: 0.32124, Validation F1: 0.42540\n",
            "Epoch 16: Training Loss: 0.30058, Validation Loss: 0.30097, Training F1: 0.36560, Validation F1: 0.28931\n",
            "Epoch 17: Training Loss: 0.27758, Validation Loss: 0.36267, Training F1: 0.43894, Validation F1: 0.26966\n",
            "Epoch 18: Training Loss: 0.27890, Validation Loss: 0.30830, Training F1: 0.42158, Validation F1: 0.33082\n",
            "Epoch 19: Training Loss: 0.28255, Validation Loss: 0.98314, Training F1: 0.40551, Validation F1: 0.36813\n",
            "Epoch 20: Training Loss: 0.27691, Validation Loss: 0.26706, Training F1: 0.42476, Validation F1: 0.41050\n",
            "Epoch 21: Training Loss: 0.27752, Validation Loss: 0.31643, Training F1: 0.44804, Validation F1: 0.31288\n",
            "Epoch 22: Training Loss: 0.27797, Validation Loss: 0.33536, Training F1: 0.45918, Validation F1: 0.30769\n",
            "Epoch 23: Training Loss: 0.26858, Validation Loss: 0.33053, Training F1: 0.43250, Validation F1: 0.49051\n",
            "Epoch 24: Training Loss: 0.25989, Validation Loss: 0.34691, Training F1: 0.50427, Validation F1: 0.14151\n",
            "Epoch 25: Training Loss: 0.26043, Validation Loss: 0.51541, Training F1: 0.51972, Validation F1: 0.10436\n",
            "Epoch 26: Training Loss: 0.26186, Validation Loss: 0.26705, Training F1: 0.50121, Validation F1: 0.37085\n",
            "Epoch 27: Training Loss: 0.24494, Validation Loss: 0.51907, Training F1: 0.53119, Validation F1: 0.26241\n",
            "Epoch 28: Training Loss: 0.26307, Validation Loss: 0.24908, Training F1: 0.49450, Validation F1: 0.45496\n",
            "Epoch 29: Training Loss: 0.24140, Validation Loss: 0.72238, Training F1: 0.57275, Validation F1: 0.62222\n",
            "Epoch 30: Training Loss: 0.24304, Validation Loss: 0.34001, Training F1: 0.55565, Validation F1: 0.14151\n",
            "Epoch 31: Training Loss: 0.24681, Validation Loss: 0.23093, Training F1: 0.55319, Validation F1: 0.63511\n",
            "Epoch 32: Training Loss: 0.24802, Validation Loss: 0.23425, Training F1: 0.55321, Validation F1: 0.46121\n",
            "Epoch 33: Training Loss: 0.25888, Validation Loss: 0.35873, Training F1: 0.53526, Validation F1: 0.26794\n",
            "Epoch 34: Training Loss: 0.25383, Validation Loss: 0.38168, Training F1: 0.52833, Validation F1: 0.47108\n",
            "Epoch 35: Training Loss: 0.24437, Validation Loss: 0.27919, Training F1: 0.56274, Validation F1: 0.34660\n",
            "Epoch 36: Training Loss: 0.24542, Validation Loss: 0.26273, Training F1: 0.56496, Validation F1: 0.53269\n",
            "Epoch 37: Training Loss: 0.22765, Validation Loss: 0.29605, Training F1: 0.61984, Validation F1: 0.60492\n",
            "Epoch 38: Training Loss: 0.23543, Validation Loss: 0.29568, Training F1: 0.56982, Validation F1: 0.28244\n",
            "Epoch 39: Training Loss: 0.23992, Validation Loss: 0.22298, Training F1: 0.60363, Validation F1: 0.65680\n",
            "Epoch 40: Training Loss: 0.23517, Validation Loss: 0.21539, Training F1: 0.60205, Validation F1: 0.62643\n",
            "Epoch 41: Training Loss: 0.22352, Validation Loss: 0.26883, Training F1: 0.66303, Validation F1: 0.40009\n",
            "Epoch 42: Training Loss: 0.22529, Validation Loss: 0.25692, Training F1: 0.64485, Validation F1: 0.50469\n",
            "Epoch 43: Training Loss: 0.22562, Validation Loss: 0.21683, Training F1: 0.65565, Validation F1: 0.61139\n",
            "Epoch 44: Training Loss: 0.22112, Validation Loss: 0.23181, Training F1: 0.67621, Validation F1: 0.51379\n",
            "Epoch 45: Training Loss: 0.22783, Validation Loss: 0.28302, Training F1: 0.64728, Validation F1: 0.54326\n",
            "Epoch 46: Training Loss: 0.22601, Validation Loss: 0.33434, Training F1: 0.64258, Validation F1: 0.29371\n",
            "Epoch 47: Training Loss: 0.22393, Validation Loss: 0.23312, Training F1: 0.66440, Validation F1: 0.59170\n",
            "Epoch 48: Training Loss: 0.22896, Validation Loss: 0.30061, Training F1: 0.65286, Validation F1: 0.30216\n",
            "Epoch 49: Training Loss: 0.21956, Validation Loss: 0.23695, Training F1: 0.64881, Validation F1: 0.60192\n",
            "Epoch 50: Training Loss: 0.21078, Validation Loss: 0.21763, Training F1: 0.70202, Validation F1: 0.61224\n",
            "Epoch 51: Training Loss: 0.22501, Validation Loss: 0.31119, Training F1: 0.67554, Validation F1: 0.33673\n",
            "Epoch 52: Training Loss: 0.21712, Validation Loss: 0.28227, Training F1: 0.67919, Validation F1: 0.48622\n",
            "Epoch 53: Training Loss: 0.20310, Validation Loss: 10.11147, Training F1: 0.69646, Validation F1: 0.00000\n",
            "Epoch 54: Training Loss: 0.21216, Validation Loss: 0.18258, Training F1: 0.69366, Validation F1: 0.76748\n",
            "Epoch 55: Training Loss: 0.21254, Validation Loss: 0.19274, Training F1: 0.70681, Validation F1: 0.76730\n",
            "Epoch 56: Training Loss: 0.21530, Validation Loss: 0.23247, Training F1: 0.66145, Validation F1: 0.62484\n",
            "Epoch 57: Training Loss: 0.21700, Validation Loss: 0.18980, Training F1: 0.67265, Validation F1: 0.75372\n",
            "Epoch 58: Training Loss: 0.21153, Validation Loss: 0.18892, Training F1: 0.70866, Validation F1: 0.69697\n",
            "Epoch 59: Training Loss: 0.21227, Validation Loss: 0.22515, Training F1: 0.70889, Validation F1: 0.70077\n",
            "Epoch 60: Training Loss: 0.21859, Validation Loss: 0.23415, Training F1: 0.68240, Validation F1: 0.68125\n",
            "Epoch 61: Training Loss: 0.20629, Validation Loss: 0.19313, Training F1: 0.69576, Validation F1: 0.69921\n",
            "Epoch 62: Training Loss: 0.20720, Validation Loss: 0.20632, Training F1: 0.70361, Validation F1: 0.66349\n",
            "Epoch 63: Training Loss: 0.20616, Validation Loss: 0.83514, Training F1: 0.69727, Validation F1: 0.32796\n",
            "Epoch 64: Training Loss: 0.20931, Validation Loss: 0.31692, Training F1: 0.69233, Validation F1: 0.67068\n",
            "Epoch 65: Training Loss: 0.21224, Validation Loss: 0.19479, Training F1: 0.68129, Validation F1: 0.73347\n",
            "Epoch 66: Training Loss: 0.20349, Validation Loss: 0.20398, Training F1: 0.70309, Validation F1: 0.73606\n",
            "Epoch 67: Training Loss: 0.19890, Validation Loss: 0.18377, Training F1: 0.72384, Validation F1: 0.74078\n",
            "Epoch 68: Training Loss: 0.20712, Validation Loss: 54.68213, Training F1: 0.70481, Validation F1: 0.26847\n",
            "Epoch 69: Training Loss: 0.20811, Validation Loss: 0.21612, Training F1: 0.66809, Validation F1: 0.72158\n",
            "Epoch 70: Training Loss: 0.20285, Validation Loss: 0.31323, Training F1: 0.70704, Validation F1: 0.41956\n",
            "Epoch 71: Training Loss: 0.19951, Validation Loss: 0.19773, Training F1: 0.73993, Validation F1: 0.76250\n",
            "Epoch 72: Training Loss: 0.19890, Validation Loss: 0.19051, Training F1: 0.71599, Validation F1: 0.76478\n",
            "Epoch 73: Training Loss: 0.19710, Validation Loss: 0.21851, Training F1: 0.73559, Validation F1: 0.67475\n",
            "Epoch 74: Training Loss: 0.19829, Validation Loss: 0.28269, Training F1: 0.73030, Validation F1: 0.53977\n",
            "Epoch 75: Training Loss: 0.19542, Validation Loss: 0.17993, Training F1: 0.72479, Validation F1: 0.73233\n",
            "Epoch 76: Training Loss: 0.19763, Validation Loss: 0.19123, Training F1: 0.70060, Validation F1: 0.77349\n",
            "Epoch 77: Training Loss: 0.19895, Validation Loss: 0.68626, Training F1: 0.71647, Validation F1: 0.53082\n",
            "Epoch 78: Training Loss: 0.19732, Validation Loss: 0.83659, Training F1: 0.69965, Validation F1: 0.58095\n",
            "Epoch 79: Training Loss: 0.20943, Validation Loss: 0.21655, Training F1: 0.69090, Validation F1: 0.72028\n",
            "Epoch 80: Training Loss: 0.18616, Validation Loss: 0.46358, Training F1: 0.73415, Validation F1: 0.36765\n",
            "Epoch 81: Training Loss: 0.19824, Validation Loss: 0.21773, Training F1: 0.70550, Validation F1: 0.62947\n",
            "Epoch 82: Training Loss: 0.19060, Validation Loss: 0.21070, Training F1: 0.73265, Validation F1: 0.69581\n",
            "Epoch 83: Training Loss: 0.19012, Validation Loss: 0.21085, Training F1: 0.73153, Validation F1: 0.71248\n",
            "Epoch 84: Training Loss: 0.19112, Validation Loss: 0.18650, Training F1: 0.74463, Validation F1: 0.73882\n",
            "Epoch 85: Training Loss: 0.19733, Validation Loss: 0.21311, Training F1: 0.70998, Validation F1: 0.70205\n",
            "Epoch 86: Training Loss: 0.19165, Validation Loss: 0.18171, Training F1: 0.72000, Validation F1: 0.77086\n",
            "Epoch 87: Training Loss: 0.18547, Validation Loss: 0.20328, Training F1: 0.76290, Validation F1: 0.68116\n",
            "Epoch 88: Training Loss: 0.19430, Validation Loss: 1.12938, Training F1: 0.70956, Validation F1: 0.25397\n",
            "Epoch 89: Training Loss: 0.19134, Validation Loss: 0.18032, Training F1: 0.72232, Validation F1: 0.74945\n",
            "Epoch 90: Training Loss: 0.18866, Validation Loss: 0.43940, Training F1: 0.72546, Validation F1: 0.29267\n",
            "Epoch 91: Training Loss: 0.19046, Validation Loss: 0.19780, Training F1: 0.72351, Validation F1: 0.73960\n",
            "Epoch 92: Training Loss: 0.18399, Validation Loss: 0.20445, Training F1: 0.75005, Validation F1: 0.73410\n",
            "Epoch 93: Training Loss: 0.18565, Validation Loss: 0.21516, Training F1: 0.74473, Validation F1: 0.74313\n",
            "Epoch 94: Training Loss: 0.18375, Validation Loss: 0.19641, Training F1: 0.74658, Validation F1: 0.74257\n",
            "Epoch 95: Training Loss: 0.18242, Validation Loss: 0.17925, Training F1: 0.75399, Validation F1: 0.80000\n",
            "Epoch 96: Training Loss: 0.19059, Validation Loss: 0.18692, Training F1: 0.75178, Validation F1: 0.75313\n",
            "Epoch 97: Training Loss: 0.18316, Validation Loss: 0.24779, Training F1: 0.75406, Validation F1: 0.68933\n",
            "Epoch 98: Training Loss: 0.17491, Validation Loss: 0.23616, Training F1: 0.76219, Validation F1: 0.64037\n",
            "Epoch 99: Training Loss: 0.18076, Validation Loss: 0.30269, Training F1: 0.75411, Validation F1: 0.62684\n",
            "Epoch 100: Training Loss: 0.17335, Validation Loss: 0.38664, Training F1: 0.77063, Validation F1: 0.37273\n",
            "Epoch 101: Training Loss: 0.17696, Validation Loss: 0.21940, Training F1: 0.75201, Validation F1: 0.72828\n",
            "Epoch 102: Training Loss: 0.17140, Validation Loss: 0.21897, Training F1: 0.78014, Validation F1: 0.68983\n",
            "Epoch 103: Training Loss: 0.18275, Validation Loss: 0.23275, Training F1: 0.75082, Validation F1: 0.66511\n",
            "Epoch 104: Training Loss: 0.18204, Validation Loss: 0.32308, Training F1: 0.76656, Validation F1: 0.31667\n",
            "Epoch 105: Training Loss: 0.17463, Validation Loss: 0.20483, Training F1: 0.76371, Validation F1: 0.77654\n",
            "Epoch 106: Training Loss: 0.18586, Validation Loss: 0.19452, Training F1: 0.72986, Validation F1: 0.72546\n",
            "Epoch 107: Training Loss: 0.16818, Validation Loss: 0.21710, Training F1: 0.78795, Validation F1: 0.73979\n",
            "Epoch 108: Training Loss: 0.17665, Validation Loss: 0.25060, Training F1: 0.76792, Validation F1: 0.62647\n",
            "Epoch 109: Training Loss: 0.18392, Validation Loss: 0.21218, Training F1: 0.75397, Validation F1: 0.59482\n",
            "Epoch 110: Training Loss: 0.16735, Validation Loss: 0.18687, Training F1: 0.77296, Validation F1: 0.63596\n",
            "Epoch 111: Training Loss: 0.17124, Validation Loss: 0.43829, Training F1: 0.75851, Validation F1: 0.20354\n",
            "Epoch 112: Training Loss: 0.16622, Validation Loss: 0.40184, Training F1: 0.76820, Validation F1: 0.49048\n",
            "Epoch 113: Training Loss: 0.17766, Validation Loss: 0.26994, Training F1: 0.75965, Validation F1: 0.64576\n",
            "Epoch 114: Training Loss: 0.17064, Validation Loss: 0.18464, Training F1: 0.77459, Validation F1: 0.70570\n",
            "Epoch 115: Training Loss: 0.16926, Validation Loss: 0.25967, Training F1: 0.77641, Validation F1: 0.72060\n",
            "Epoch 116: Training Loss: 0.17477, Validation Loss: 0.34637, Training F1: 0.75149, Validation F1: 0.37500\n",
            "Epoch 117: Training Loss: 0.17137, Validation Loss: 0.28667, Training F1: 0.77999, Validation F1: 0.65863\n",
            "Epoch 118: Training Loss: 0.16810, Validation Loss: 0.18993, Training F1: 0.77565, Validation F1: 0.77190\n",
            "Epoch 119: Training Loss: 0.16223, Validation Loss: 0.26716, Training F1: 0.79098, Validation F1: 0.48576\n",
            "Epoch 120: Training Loss: 0.16599, Validation Loss: 0.22700, Training F1: 0.77551, Validation F1: 0.74028\n",
            "Epoch 121: Training Loss: 0.17043, Validation Loss: 0.55111, Training F1: 0.75592, Validation F1: 0.21047\n",
            "Epoch 122: Training Loss: 0.15973, Validation Loss: 0.20062, Training F1: 0.80335, Validation F1: 0.72934\n",
            "Epoch 123: Training Loss: 0.17267, Validation Loss: 0.33776, Training F1: 0.77298, Validation F1: 0.58152\n",
            "Epoch 124: Training Loss: 0.16747, Validation Loss: 0.20996, Training F1: 0.78470, Validation F1: 0.67240\n",
            "Epoch 125: Training Loss: 0.15813, Validation Loss: 0.17551, Training F1: 0.79281, Validation F1: 0.77926\n",
            "Epoch 126: Training Loss: 0.15799, Validation Loss: 0.34594, Training F1: 0.81562, Validation F1: 0.71905\n",
            "Epoch 127: Training Loss: 0.16800, Validation Loss: 0.27820, Training F1: 0.78337, Validation F1: 0.56686\n",
            "Epoch 128: Training Loss: 0.16702, Validation Loss: 0.29712, Training F1: 0.77041, Validation F1: 0.60952\n",
            "Epoch 129: Training Loss: 0.14996, Validation Loss: 0.25822, Training F1: 0.82829, Validation F1: 0.74752\n",
            "Epoch 130: Training Loss: 0.15666, Validation Loss: 0.18874, Training F1: 0.78426, Validation F1: 0.74011\n",
            "Epoch 131: Training Loss: 0.16071, Validation Loss: 0.38070, Training F1: 0.80643, Validation F1: 0.66748\n",
            "Epoch 132: Training Loss: 0.15509, Validation Loss: 0.25174, Training F1: 0.79854, Validation F1: 0.63215\n",
            "Epoch 133: Training Loss: 0.16393, Validation Loss: 0.17545, Training F1: 0.78179, Validation F1: 0.79500\n",
            "Epoch 134: Training Loss: 0.14524, Validation Loss: 0.25761, Training F1: 0.82544, Validation F1: 0.60519\n",
            "Epoch 135: Training Loss: 0.15272, Validation Loss: 0.22075, Training F1: 0.80960, Validation F1: 0.74346\n",
            "Epoch 136: Training Loss: 0.15511, Validation Loss: 0.19669, Training F1: 0.79759, Validation F1: 0.76063\n",
            "Epoch 137: Training Loss: 0.15432, Validation Loss: 0.21885, Training F1: 0.80362, Validation F1: 0.68393\n",
            "Epoch 138: Training Loss: 0.15637, Validation Loss: 0.31954, Training F1: 0.79540, Validation F1: 0.68753\n",
            "Epoch 139: Training Loss: 0.15627, Validation Loss: 0.33843, Training F1: 0.79722, Validation F1: 0.66711\n",
            "Epoch 140: Training Loss: 0.14786, Validation Loss: 0.25189, Training F1: 0.82351, Validation F1: 0.65107\n",
            "Epoch 141: Training Loss: 0.14998, Validation Loss: 0.20165, Training F1: 0.79789, Validation F1: 0.76019\n",
            "Epoch 142: Training Loss: 0.15621, Validation Loss: 0.25003, Training F1: 0.78571, Validation F1: 0.63926\n",
            "Epoch 143: Training Loss: 0.15102, Validation Loss: 0.26650, Training F1: 0.81549, Validation F1: 0.63615\n",
            "Epoch 144: Training Loss: 0.15283, Validation Loss: 0.20748, Training F1: 0.79314, Validation F1: 0.74199\n",
            "Epoch 145: Training Loss: 0.14101, Validation Loss: 0.22490, Training F1: 0.84646, Validation F1: 0.73311\n",
            "Epoch 146: Training Loss: 0.14141, Validation Loss: 0.24119, Training F1: 0.81733, Validation F1: 0.77374\n",
            "Epoch 147: Training Loss: 0.15897, Validation Loss: 0.21911, Training F1: 0.78628, Validation F1: 0.75988\n",
            "Epoch 148: Training Loss: 0.14999, Validation Loss: 0.20869, Training F1: 0.80862, Validation F1: 0.74151\n",
            "Epoch 149: Training Loss: 0.14203, Validation Loss: 0.22290, Training F1: 0.83106, Validation F1: 0.72384\n",
            "Epoch 150: Training Loss: 0.13638, Validation Loss: 0.37962, Training F1: 0.82849, Validation F1: 0.47121\n",
            "Epoch 151: Training Loss: 0.14625, Validation Loss: 0.22371, Training F1: 0.81715, Validation F1: 0.69144\n",
            "Epoch 152: Training Loss: 0.14963, Validation Loss: 0.21081, Training F1: 0.82544, Validation F1: 0.71058\n",
            "Epoch 153: Training Loss: 0.14018, Validation Loss: 0.18560, Training F1: 0.81948, Validation F1: 0.78674\n",
            "Epoch 154: Training Loss: 0.14230, Validation Loss: 0.24089, Training F1: 0.82207, Validation F1: 0.72823\n",
            "Epoch 155: Training Loss: 0.13680, Validation Loss: 0.24427, Training F1: 0.82859, Validation F1: 0.74101\n",
            "Epoch 156: Training Loss: 0.12794, Validation Loss: 0.39200, Training F1: 0.85119, Validation F1: 0.55945\n",
            "Epoch 157: Training Loss: 0.13793, Validation Loss: 3.31173, Training F1: 0.82764, Validation F1: 0.49981\n",
            "Epoch 158: Training Loss: 0.14239, Validation Loss: 0.28359, Training F1: 0.83770, Validation F1: 0.69833\n",
            "Epoch 159: Training Loss: 0.13097, Validation Loss: 0.25570, Training F1: 0.84466, Validation F1: 0.71886\n",
            "Epoch 160: Training Loss: 0.13411, Validation Loss: 0.23971, Training F1: 0.83095, Validation F1: 0.73964\n",
            "Epoch 161: Training Loss: 0.13557, Validation Loss: 0.25100, Training F1: 0.82809, Validation F1: 0.74155\n",
            "Epoch 162: Training Loss: 0.13417, Validation Loss: 0.24976, Training F1: 0.84037, Validation F1: 0.58557\n",
            "Epoch 163: Training Loss: 0.13445, Validation Loss: 0.34154, Training F1: 0.83123, Validation F1: 0.57412\n",
            "Epoch 164: Training Loss: 0.12513, Validation Loss: 0.35863, Training F1: 0.84497, Validation F1: 0.44087\n",
            "Epoch 165: Training Loss: 0.13098, Validation Loss: 0.24249, Training F1: 0.83259, Validation F1: 0.73644\n",
            "Epoch 166: Training Loss: 0.12843, Validation Loss: 0.29633, Training F1: 0.84036, Validation F1: 0.70047\n",
            "Epoch 167: Training Loss: 0.13771, Validation Loss: 0.25094, Training F1: 0.84605, Validation F1: 0.68182\n",
            "Epoch 168: Training Loss: 0.12869, Validation Loss: 0.56082, Training F1: 0.83154, Validation F1: 0.63650\n",
            "Epoch 169: Training Loss: 0.13429, Validation Loss: 0.19656, Training F1: 0.81560, Validation F1: 0.76252\n",
            "Epoch 170: Training Loss: 0.13597, Validation Loss: 0.34220, Training F1: 0.82507, Validation F1: 0.55460\n",
            "Epoch 171: Training Loss: 0.13083, Validation Loss: 0.22473, Training F1: 0.82321, Validation F1: 0.71159\n",
            "Epoch 172: Training Loss: 0.13175, Validation Loss: 0.19495, Training F1: 0.83356, Validation F1: 0.79546\n",
            "Epoch 173: Training Loss: 0.13316, Validation Loss: 0.27865, Training F1: 0.82573, Validation F1: 0.75333\n",
            "Epoch 174: Training Loss: 0.12258, Validation Loss: 0.46523, Training F1: 0.83701, Validation F1: 0.59017\n",
            "Epoch 175: Training Loss: 0.11963, Validation Loss: 0.29277, Training F1: 0.85230, Validation F1: 0.61033\n",
            "Epoch 176: Training Loss: 0.12285, Validation Loss: 0.33133, Training F1: 0.84463, Validation F1: 0.72609\n",
            "Epoch 177: Training Loss: 0.11906, Validation Loss: 0.92159, Training F1: 0.87271, Validation F1: 0.67725\n",
            "Epoch 178: Training Loss: 0.11534, Validation Loss: 0.21254, Training F1: 0.86637, Validation F1: 0.78994\n",
            "Epoch 179: Training Loss: 0.11380, Validation Loss: 0.26524, Training F1: 0.86785, Validation F1: 0.67797\n",
            "Epoch 180: Training Loss: 0.13690, Validation Loss: 0.32014, Training F1: 0.82436, Validation F1: 0.52191\n",
            "Epoch 181: Training Loss: 0.10714, Validation Loss: 0.40776, Training F1: 0.87819, Validation F1: 0.51849\n",
            "Epoch 182: Training Loss: 0.13724, Validation Loss: 0.43432, Training F1: 0.81276, Validation F1: 0.65333\n",
            "Epoch 183: Training Loss: 0.10967, Validation Loss: 0.24679, Training F1: 0.86896, Validation F1: 0.75781\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "INSomwSCR_Dx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "UecDgKHYlkgT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"email@gmail.com\"\n",
        "!git config --global user.name \"username\""
      ],
      "metadata": {
        "id": "_zOSPwk1lpNJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Changed transformations for training\""
      ],
      "metadata": {
        "id": "1Y1_yBUVl6hM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://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@github.com/teodoraspasojevic/ResNet-PyTorch-Implementation.git"
      ],
      "metadata": {
        "id": "XLObhCXlmO1z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "id": "Zw2vIxe6ptRI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ailjATTEuxfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}